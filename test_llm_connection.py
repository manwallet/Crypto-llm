#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
LLMè¿æ¥æµ‹è¯•è„šæœ¬

æ­¤è„šæœ¬æµ‹è¯•ä¸è¯­è¨€æ¨¡å‹APIçš„è¿æ¥å¹¶éªŒè¯æ¨¡å‹é—´é€šä¿¡åŠŸèƒ½æ˜¯å¦æ­£å¸¸ã€‚
å®ƒå¯¹ç³»ç»Ÿä¸­ä½¿ç”¨çš„æ¯ä¸ªAIä»£ç†è§’è‰²æ‰§è¡Œç®€å•æµ‹è¯•ï¼Œä»¥ç¡®ä¿APIé…ç½®æ­£ç¡®ã€‚
"""

import os
import sys
import json
from datetime import datetime
from dotenv import load_dotenv

# ç¡®ä¿èƒ½å¤Ÿå¯¼å…¥ä¸»æ¨¡å—
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from modules.llm_agent_manager import LLMAgentManager

class LLMConnectionTester:
    """æµ‹è¯•LLM APIè¿æ¥å’Œå¤šä»£ç†é€šä¿¡çš„ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•å™¨"""
        # åŠ è½½ç¯å¢ƒå˜é‡
        load_dotenv()
        print("åŠ è½½ç¯å¢ƒå˜é‡å®Œæˆ")
        
        # åˆå§‹åŒ–LLMä»£ç†ç®¡ç†å™¨
        self.llm_agent = LLMAgentManager()
        print("åˆå§‹åŒ–LLMä»£ç†ç®¡ç†å™¨å®Œæˆ")
        
    def test_api_connection(self):
        """æµ‹è¯•APIè¿æ¥æ˜¯å¦æ­£å¸¸å·¥ä½œ"""
        print("\n=== æµ‹è¯•APIè¿æ¥ ===")
        
        # è·å–å½“å‰APIé…ç½®
        config = self.llm_agent.get_api_config()
        print(f"å½“å‰APIé…ç½®:")
        print(f"- åŸºç¡€URL: {config['base_url'] or 'ä½¿ç”¨é»˜è®¤OpenAI API'}")
        print(f"- ç»„ç»‡ID: {config['org_id'] or 'æœªè®¾ç½®'}")
        print(f"- æ¨¡å‹é…ç½®:")
        for role, model in config['models'].items():
            print(f"  - {role}: {model}")
        
        # ç®€å•æµ‹è¯•è°ƒç”¨
        try:
            response = self.llm_agent.openai.chat.completions.create(
                model=self.llm_agent.analyst_agent,
                messages=[{"role": "user", "content": "ç®€å•æµ‹è¯•å¥å­ï¼Œè¯·å›å¤'APIè¿æ¥æ­£å¸¸'"}],
                max_tokens=20
            )
            
            content = response.choices[0].message.content
            print(f"\næµ‹è¯•å“åº”: {content}")
            
            if "APIè¿æ¥æ­£å¸¸" in content or "è¿æ¥" in content:
                print("âœ… APIè¿æ¥æµ‹è¯•æˆåŠŸ!")
            else:
                print("âš ï¸ APIå“åº”å†…å®¹ä¸é¢„æœŸä¸ç¬¦ï¼Œä½†è¿æ¥å¯èƒ½æ­£å¸¸")
                
        except Exception as e:
            print(f"âŒ APIè¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
            
        return True
    
    def test_analyst_agent(self):
        """æµ‹è¯•å¸‚åœºåˆ†æå¸ˆä»£ç†"""
        print("\n=== æµ‹è¯•å¸‚åœºåˆ†æå¸ˆä»£ç† ===")
        
        try:
            prompt = "åˆ†ææ¯”ç‰¹å¸å½“å‰å¸‚åœºçŠ¶å†µï¼Œç®€è¦å›ç­”ä¸è¶…è¿‡50å­—ã€‚"
            
            response = self.llm_agent.openai.chat.completions.create(
                model=self.llm_agent.analyst_agent,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=100
            )
            
            content = response.choices[0].message.content
            print(f"åˆ†æå¸ˆå“åº”: {content}")
            print("âœ… å¸‚åœºåˆ†æå¸ˆä»£ç†æµ‹è¯•æˆåŠŸ!")
            
        except Exception as e:
            print(f"âŒ å¸‚åœºåˆ†æå¸ˆä»£ç†æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
            
        return True
    
    def test_trader_agent(self):
        """æµ‹è¯•äº¤æ˜“å†³ç­–è€…ä»£ç†"""
        print("\n=== æµ‹è¯•äº¤æ˜“å†³ç­–è€…ä»£ç† ===")
        
        try:
            prompt = """
è¯·åŸºäºä»¥ä¸‹å¸‚åœºåˆ†ææå‡ºä¸€ä¸ªç®€çŸ­çš„äº¤æ˜“å»ºè®®:
"æ¯”ç‰¹å¸ç›®å‰ä»·æ ¼29500ç¾å…ƒï¼Œå¤„äºç›˜æ•´é˜¶æ®µï¼Œæ”¯æ’‘ä½åœ¨28000ç¾å…ƒï¼Œé˜»åŠ›ä½åœ¨30000ç¾å…ƒã€‚"

ä»¥JSONæ ¼å¼è¾“å‡ºä½ çš„å†³å®šï¼Œæ ¼å¼å¦‚ä¸‹:
{
  "action": "å¼€å¤š/å¼€ç©º/å¹³ä»“/è§‚æœ›",
  "price": "å…·ä½“ä»·æ ¼æˆ–ä»·æ ¼åŒºé—´",
  "quantity": "å…·ä½“æ•°é‡æˆ–è´¦æˆ·ç™¾åˆ†æ¯”",
  "stop_loss": "å…·ä½“ä»·æ ¼",
  "take_profit": "å…·ä½“ä»·æ ¼",
  "confidence": "1-10",
  "reason": "ç®€è¦å†³ç­–ç†ç”±"
}
"""
            
            response = self.llm_agent.openai.chat.completions.create(
                model=self.llm_agent.trader_agent,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=200
            )
            
            content = response.choices[0].message.content
            print(f"äº¤æ˜“è€…å“åº”: {content}")
            
            # å°è¯•è§£æJSONå“åº”
            try:
                # æå–JSONéƒ¨åˆ†
                if "```json" in content:
                    # å»æ‰ markdown æ ¼å¼
                    json_text = content.split("```json")[1].split("```")[0].strip()
                elif "```" in content:
                    json_text = content.split("```")[1].strip()
                else:
                    json_text = content
                    
                decision = json.loads(json_text)
                print("æˆåŠŸè§£æJSONå†³ç­–:")
                for key, value in decision.items():
                    print(f"- {key}: {value}")
                    
                print("âœ… äº¤æ˜“å†³ç­–è€…ä»£ç†æµ‹è¯•æˆåŠŸ!")
            except:
                print("âš ï¸ æ— æ³•è§£æJSONå“åº”ï¼Œä½†APIè°ƒç”¨æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ äº¤æ˜“å†³ç­–è€…ä»£ç†æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
            
        return True
    
    def test_risk_agent(self):
        """æµ‹è¯•é£é™©ç®¡ç†è€…ä»£ç†"""
        print("\n=== æµ‹è¯•é£é™©ç®¡ç†è€…ä»£ç† ===")
        
        try:
            prompt = """
è¯„ä¼°ä»¥ä¸‹äº¤æ˜“ç­–ç•¥çš„é£é™©:
"å¼€å¤šBTCï¼Œå…¥åœºä»·29500ç¾å…ƒï¼Œæ­¢æŸ28800ç¾å…ƒï¼Œæ­¢ç›ˆ31000ç¾å…ƒï¼Œä½¿ç”¨è´¦æˆ·20%èµ„é‡‘ã€‚"

å›å¤ä¸€ä¸ª1-10çš„é£é™©è¯„åˆ†å’Œç®€çŸ­è§£é‡Šã€‚
"""
            
            response = self.llm_agent.openai.chat.completions.create(
                model=self.llm_agent.risk_agent,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=100
            )
            
            content = response.choices[0].message.content
            print(f"é£é™©ç®¡ç†è€…å“åº”: {content}")
            print("âœ… é£é™©ç®¡ç†è€…ä»£ç†æµ‹è¯•æˆåŠŸ!")
            
        except Exception as e:
            print(f"âŒ é£é™©ç®¡ç†è€…ä»£ç†æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
            
        return True
    
    def test_multi_agent_debate(self):
        """æµ‹è¯•ä»£ç†é—´è¾©è®ºåŠŸèƒ½"""
        print("\n=== æµ‹è¯•ä»£ç†é—´è¾©è®ºåŠŸèƒ½ ===")
        
        try:
            prompt = """
ä½ æ˜¯åŠ å¯†è´§å¸äº¤æ˜“è¾©è®ºçš„åè°ƒè€…ã€‚
äº¤æ˜“ç­–ç•¥å¸ˆå»ºè®®: "å¼€å¤šBTCï¼Œå…¥åœºä»·29500ç¾å…ƒï¼Œæ­¢æŸ28800ç¾å…ƒï¼Œæ­¢ç›ˆ31000ç¾å…ƒï¼Œä½¿ç”¨è´¦æˆ·20%èµ„é‡‘ã€‚"
é£é™©ç®¡ç†ä¸“å®¶è¯„ä¼°: "é£é™©è¯„åˆ†7/10ã€‚é£é™©è¾ƒé«˜ï¼Œå»ºè®®å‡å°‘ä»“ä½è‡³10%å¹¶æé«˜æ­¢æŸä½ã€‚"

è¯·ç»„ç»‡ä¸€æ¬¡ç®€çŸ­çš„è™šæ‹Ÿè¾©è®ºï¼Œå¹¶æå‡ºä¸€ä¸ªå¹³è¡¡çš„å»ºè®®ã€‚æœ€å¤š100å­—ã€‚
"""
            
            response = self.llm_agent.openai.chat.completions.create(
                model=self.llm_agent.debate_agent,
                messages=[{"role": "user", "content": prompt}],
                max_tokens=150
            )
            
            content = response.choices[0].message.content
            print(f"è¾©è®ºåè°ƒè€…å“åº”: {content}")
            print("âœ… å¤šä»£ç†è¾©è®ºåŠŸèƒ½æµ‹è¯•æˆåŠŸ!")
            
        except Exception as e:
            print(f"âŒ å¤šä»£ç†è¾©è®ºåŠŸèƒ½æµ‹è¯•å¤±è´¥: {str(e)}")
            return False
            
        return True
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("==================================")
        print("LLMè¿æ¥å’Œå¤šä»£ç†é€šä¿¡æµ‹è¯•")
        print("==================================")
        print(f"æµ‹è¯•æ—¶é—´: {datetime.now()}")
        
        results = {}
        
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        results["api_connection"] = self.test_api_connection()
        
        # åªæœ‰åœ¨APIè¿æ¥æˆåŠŸçš„æƒ…å†µä¸‹ç»§ç»­å…¶ä»–æµ‹è¯•
        if results["api_connection"]:
            results["analyst_agent"] = self.test_analyst_agent()
            results["trader_agent"] = self.test_trader_agent()
            results["risk_agent"] = self.test_risk_agent()
            results["multi_agent_debate"] = self.test_multi_agent_debate()
        
        # æ‰“å°æ€»ç»“
        print("\n==================================")
        print("æµ‹è¯•ç»“æœæ‘˜è¦")
        print("==================================")
        
        for test, result in results.items():
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"{test}: {status}")
        
        all_passed = all(results.values())
        if all_passed:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! LLMé€šä¿¡åŠŸèƒ½æ­£å¸¸ã€‚")
        else:
            print("\nâš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ã€‚è¯·æ£€æŸ¥APIé…ç½®å’Œç½‘ç»œè¿æ¥ã€‚")
        
        return all_passed

# ç›´æ¥è¿è¡Œ
if __name__ == "__main__":
    tester = LLMConnectionTester()
    tester.run_all_tests() 